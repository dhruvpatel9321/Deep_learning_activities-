{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>How to train Detectron2 with Custom COCO Datasets</h1> \n",
    "\n",
    "<img src=\"1.png\">\n",
    "\n",
    "Along with the pytorch 1.3 release came with the next generation ground-up rewrite of its previous object detection framework, now called **Detectron2**.This tutorial will help you to get started with this framework(Detectron2) by training instance segmentation model with your custom COCO datasets.\n",
    "\n",
    "We will run Detectron2 framework in GoogleColab so you don't need to worry about setting up the development on your machine before getting comfortable with pytorch 1.4 and Detectron2.\n",
    "\n",
    "Our [Colab](https://colab.research.google.com/drive/1p8rVdTyRdUL8BtxEFGd2wT2oWipbkfFJ) notebook available here!\n",
    "\n",
    "## Install Detectron2 \n",
    "\n",
    "Just run these 4 lines command in the Colab notebook, it'll install new version of pytorch 1.4 and Detectron2.\n",
    "\n",
    "<img src=\"2.png\">\n",
    "\n",
    "click \"RESTART RUNTIME\" in the cell's output to let your installation take effect.\n",
    "\n",
    "<img src=\"3.png\">\n",
    "\n",
    "## Register a COCO dataset\n",
    "\n",
    "In Detectron2 we have to tell it, how to obtain your dataset, we are going to register it first.\n",
    "\n",
    "To demonstrate this process, i have taken my own <u>*sample segmentation datatset*</u>. Which only have three classes: Helmet, Person, Car. We'll train this segmentation model from an existing model which is already pre-trained in the COCO dataset, available in the detectron2's model zoo.\n",
    "\n",
    "You can download dataset like this\n",
    "\n",
    "<img src=\"10.png\">\n",
    "\n",
    "or, you can upload your dataset like this\n",
    "\n",
    "<img src=\"11.png\">\n",
    "\n",
    "Register **sample** dataset to detectron2.\n",
    "\n",
    "<img src=\"12.png\">\n",
    "\n",
    "Each dataset in Detectron2 is associated with some metadata. In our case it is accessible by calling <mark style=\"background-color: lightblue\">sample_metadata = MetadataCatalog.get(\"sample\")</mark> , you'll get like\n",
    "\n",
    "<mark style=\"background-color: grey\">Metadata(evaluator_type='coco', image_root='./data/images', json_file='./data/trainval.json', name='sample', thing_classes=['Car', 'Helmet', 'Person'], thing_dataset_id_to_contiguous_id={0: 0, 1: 1, 2: 2})</mark>\n",
    "\n",
    "To get the actual internal representation of the catalog stores information about the datasets, you can obtain it by writing this <mark style=\"background-color: grey\">dataset_dicts = DatasetCatalog.get(\"sample\")</mark> inside the colab notebook cell.The internal format uses one dict to present annotation of one images.\n",
    "\n",
    "To verfiy the data loading is correct is by visualizing the annotations of randomly selected samples in the dataset.\n",
    "\n",
    "<img src=\"13.png\">\n",
    "\n",
    "One of the images will show this\n",
    "\n",
    "<img src=\"14.png\">\n",
    "\n",
    "## Train the model\n",
    "\n",
    "Now, let’s fine-tune a coco-pretrained R50-FPN Mask R-CNN model on sample dataset. It takes around ~2 minutes to train 300 iterations on Colab’s K80 GPU.\n",
    "\n",
    "<img src=\"15.png\">\n",
    "\n",
    "In case you switched with your own dataset, change number of classes, learning rate, or max iteration accordingly.\n",
    "\n",
    "<img src=\"16.png\">\n",
    "\n",
    "## Make a prediction\n",
    "\n",
    "Now, we can perfrom inference with trained model on the sample dataset. For that, first create predictor using the model we trained: \n",
    "\n",
    "<img src=\"17.png\">\n",
    "\n",
    "Then we randomly select several samples to visualize the prediction results.\n",
    "\n",
    "<img src=\"18.png\">\n",
    "\n",
    "Here is what we get with the sample image with prediction overlayed.\n",
    "\n",
    "<img src=\"19.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
